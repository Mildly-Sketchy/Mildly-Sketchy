{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kat's Scraper Notebook\n",
    "## Code Fellows 401d8 Python Midterm\n",
    "Scrapes Indeed for salary information for a given keyword in a given city. Keywords are a list and multiple arguments are acceptable, but note that adding additional keywords drastically increases the time it takes for the scrape to run, since it is currently searching OR, not AND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define city and keywords\n",
    "Accepts one city and multiple keywords in a list. Multi-word keywords must be separated with a plus sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Seattle'\n",
    "keywords = ['UX+designer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scraper itself, using BeautifulSoup\n",
    "Creates a dataframe from the results of the scrap. Also handles cleaning up of some data in the salary field, since Indeed salary fields come in a variety of formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_template = 'https://www.indeed.com/jobs?q={}&l={}&fromage=any&limit=100'\n",
    "max_results = 100\n",
    "\n",
    "df = pd.DataFrame(columns=['ux'])\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "for keyword in keywords:\n",
    "    for start in range(0, max_results):\n",
    "        url = url_template.format(keyword, city)\n",
    "        http = urllib3.PoolManager()\n",
    "        response = http.request('GET', url)\n",
    "        soups = BeautifulSoup(response.data.decode('utf-8'), 'html.parser')\n",
    "        for b in soups.find_all('div', attrs={'class': ' row result'}):\n",
    "            try:\n",
    "                salary = b.find('span', attrs={'class': 'no-wrap'}).text\n",
    "            except AttributeError:\n",
    "                salary = 'NA'\n",
    "            df = df.append({'ux': salary}, ignore_index=True)\n",
    "\n",
    "            df.ux.replace(regex=True,inplace=True,to_replace='\\n',value='')\n",
    "            df.ux.replace(regex=True,inplace=True,to_replace='$',value='')\n",
    "            df.ux.replace(regex=True,inplace=True,to_replace=' a year',value='')\n",
    "            df.ux.replace(regex=True,inplace=True,to_replace='(Indeed est.)',value='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "The next three cells clean up some data for us. We eliminate rows where there is no salary, remove 'a year', comma separation, and dollar signs. We also eliminate any rows that contain 'a day,' 'an hour,' or 'a month,' since we only want to work with annual salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('ux != \"NA\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.ux.str.contains('a day') == False]\n",
    "df = df[df.ux.str.contains('an hour') == False]\n",
    "df = df[df.ux.str.contains('a month') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ux = df.ux.str.replace('a year', '').str.replace(',', '').str.replace('$', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just take a peek at the data to confirm the above reformatting is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>86000 - 110000 ()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>74000 - 94000 ()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>64000 - 81000 ()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>78000 - 100000 ()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>83000 - 105000 ()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ux\n",
       "882                  86000 - 110000 ()\n",
       "883                   74000 - 94000 ()\n",
       "887                   64000 - 81000 ()\n",
       "889                  78000 - 100000 ()\n",
       "890                  83000 - 105000 ()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking lowest in the range\n",
    "Since most of the salaries are listed as a range, we assume the worst-case scenario by splitting the salary on the dash and assigning the first index as a float to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_salaries = []\n",
    "for i in df.ux:\n",
    "    a = i.split('-')\n",
    "    cleaned_salaries.append(float(a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reassigning salaries\n",
    "This replaces the salary column in the dataframe with the values from the list we made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ux = cleaned_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to CSV\n",
    "We write our results to a CSV because this scrape is kind of large and it takes foreverrrrr. We want to do things with this data, but we don't want to have to run the scrapes repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('uxresults.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's chart some salaries!\n",
    "First, read them into dataframes from the CSVs we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_plus = pd.read_csv('cplusresults.csv')\n",
    "python = pd.read_csv('pythonresults.csv')\n",
    "javascript = pd.read_csv('javascriptresults.csv')\n",
    "java = pd.read_csv('javaresults.csv')\n",
    "php = pd.read_csv('phpresults.csv')\n",
    "csharp = pd.read_csv('csharpresults.csv')\n",
    "datascience = pd.read_csv('datascienceresults.csv')\n",
    "softwaredev = pd.read_csv('softwaredevresults.csv')\n",
    "webdev = pd.read_csv('webdevresults.csv')\n",
    "dba = pd.read_csv('DBAresults.csv')\n",
    "ux = pd.read_csv('uxresults.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating them into relevant dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = pd.concat([c_plus, python, javascript, java, php, csharp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.concat([datascience, softwaredev, webdev, dba, ux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get median values for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_languages = languages.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_jobs = jobs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
